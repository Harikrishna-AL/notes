<!DOCTYPE html>






























<html
  class="not-ready text-sm lg:text-base"
  style="--bg: #faf6f1"
  lang="en-us"
>
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta
    name="viewport"
    content="width=device-width, initial-scale=1, shrink-to-fit=no"
  />

  
  <title>Diffusion - Notes</title>

  
  <meta name="theme-color" />

  
  
  
  <meta name="description" content="Denoising Diffusion Probablistic Models This note is about the diffusion model. It will cover about it&rsquo;s working and implementation both mathematically and code wise. Diffusion is one of the latest techniques used to generate new images by basically destroy them by adding more and more noise. So a basic diffusion model will contain a noise scheduler, a neural network to predict the noise in an image at given timestamp (t) (U-Net is this case) and a loss function which enables the model to learn from dataset." />
  <meta name="author" content="Notes" />
  

  
  
  
  
  
  
  <link rel="preload stylesheet" as="style" href="https://harikrishna-al.github.io/notes/main.min.css" />

  
  <script
    defer
    src="https://harikrishna-al.github.io/notes/highlight.min.js"
    onload="hljs.initHighlightingOnLoad();"
  ></script>
  

  
   
  <link rel="preload" as="image" href="https://harikrishna-al.github.io/notes/theme.png" />

  
  
  
  <link rel="preload" as="image" href="https://avatars.githubusercontent.com/u/91690484?v=4" />
  
  

  

  
  <link rel="icon" href="https://harikrishna-al.github.io/notes/favicon.ico" />
  <link rel="apple-touch-icon" href="https://harikrishna-al.github.io/notes/apple-touch-icon.png" />

  
  <meta name="generator" content="Hugo 0.111.3">

  
  

  
  
  
  
  
  
  
  <meta property="og:title" content="Diffusion" />
<meta property="og:description" content="Denoising Diffusion Probablistic Models This note is about the diffusion model. It will cover about it&rsquo;s working and implementation both mathematically and code wise. Diffusion is one of the latest techniques used to generate new images by basically destroy them by adding more and more noise. So a basic diffusion model will contain a noise scheduler, a neural network to predict the noise in an image at given timestamp (t) (U-Net is this case) and a loss function which enables the model to learn from dataset." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://harikrishna-al.github.io/notes/posts/diffusion/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-02-21T22:39:12+05:30" />
<meta property="article:modified_time" content="2023-02-21T22:39:12+05:30" />

  
  <meta itemprop="name" content="Diffusion">
<meta itemprop="description" content="Denoising Diffusion Probablistic Models This note is about the diffusion model. It will cover about it&rsquo;s working and implementation both mathematically and code wise. Diffusion is one of the latest techniques used to generate new images by basically destroy them by adding more and more noise. So a basic diffusion model will contain a noise scheduler, a neural network to predict the noise in an image at given timestamp (t) (U-Net is this case) and a loss function which enables the model to learn from dataset."><meta itemprop="datePublished" content="2023-02-21T22:39:12+05:30" />
<meta itemprop="dateModified" content="2023-02-21T22:39:12+05:30" />
<meta itemprop="wordCount" content="307">
<meta itemprop="keywords" content="" />
  
  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Diffusion"/>
<meta name="twitter:description" content="Denoising Diffusion Probablistic Models This note is about the diffusion model. It will cover about it&rsquo;s working and implementation both mathematically and code wise. Diffusion is one of the latest techniques used to generate new images by basically destroy them by adding more and more noise. So a basic diffusion model will contain a noise scheduler, a neural network to predict the noise in an image at given timestamp (t) (U-Net is this case) and a loss function which enables the model to learn from dataset."/>

  
  
</head>

  <body class="text-black duration-200 ease-out dark:text-white">
    <header class="mx-auto flex h-[5rem] max-w-3xl px-8 lg:justify-center">
  <div class="relative z-50 mr-auto flex items-center">
    <a
      class="-translate-x-[1px] -translate-y-0.5 text-3xl font-bold"
      href="https://harikrishna-al.github.io/"
      >Notes</a
    >
    <div
      class="btn-dark text-[0] ml-6 h-6 w-6 shrink-0 cursor-pointer [background:url(./theme.png)_left_center/_auto_theme('spacing.6')_no-repeat] [transition:_background-position_0.4s_steps(5)] dark:[background-position:right]"
      role="button"
      aria-label="Dark"
    ></div>
  </div>

  <div
    class="btn-menu relative z-50 -mr-8 flex h-[5rem] w-[5rem] shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden"
    role="button"
    aria-label="Menu"
  ></div>

  
  <script>
    
    const htmlClass = document.documentElement.classList;
    setTimeout(() => {
      htmlClass.remove('not-ready');
    }, 10);

    
    const btnMenu = document.querySelector('.btn-menu');
    btnMenu.addEventListener('click', () => {
      htmlClass.toggle('open');
    });

    
    const metaTheme = document.querySelector('meta[name="theme-color"]');
    const lightBg = `"#faf6f1"`.replace(/"/g, '');
    const setDark = (isDark) => {
      metaTheme.setAttribute('content', isDark ? '#000' : lightBg);
      htmlClass[isDark ? 'add' : 'remove']('dark');
      localStorage.setItem('dark', isDark);
    };

    
    const darkScheme = window.matchMedia('(prefers-color-scheme: dark)');
    if (htmlClass.contains('dark')) {
      setDark(true);
    } else {
      const darkVal = localStorage.getItem('dark');
      setDark(darkVal ? darkVal === 'true' : darkScheme.matches);
    }

    
    darkScheme.addEventListener('change', (event) => {
      setDark(event.matches);
    });

    
    const btnDark = document.querySelector('.btn-dark');
    btnDark.addEventListener('click', () => {
      setDark(localStorage.getItem('dark') !== 'true');
    });
  </script>

  <div
    class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full select-none flex-col justify-center pb-16 duration-200 dark:bg-black lg:static lg:h-auto lg:flex-row lg:!bg-transparent lg:pb-0 lg:transition-none"
  >
    
    

    
  </div>
</header>


    <main
      class="prose prose-neutral relative mx-auto min-h-[calc(100%-10rem)] max-w-3xl px-8 pt-16 pb-24 dark:prose-invert"
    >
      

<article>
  <header class="mb-20">
    <h1 class="!my-0 pb-2.5">Diffusion</h1>

    
    <div class="text-sm opacity-60">
      
      <time>Feb 21, 2023</time>
      
      
      
      
    </div>
    
  </header>

  <section><h1 id="denoising-diffusion-probablistic-models"><strong>Denoising Diffusion Probablistic Models</strong></h1>
<p>This note is about the diffusion model. It will cover about it&rsquo;s working and implementation both mathematically and code wise. Diffusion is one of the latest techniques used to generate new images by basically destroy them by adding more and more noise. So a basic diffusion model will contain a noise scheduler, a neural network to predict the noise in an image at given timestamp (t) (U-Net is this case) and a loss function which enables the model to learn from dataset.</p>
<ul>
<li>
<h2 id="noise-scheduler-forward-diffusion">Noise Scheduler (Forward Diffusion)</h2>
<p>The job of the noise scheduler is to add noise into the image during different timestamps by increasing it in a linear, quadratic and other fashions. We&rsquo;ll be using linear in our case.
This adds noise to the image keeping mean as <em><strong>sqrt(1 - beeta)</strong></em> and variance as <em><strong>beeta</strong></em>. This can be seen similar to a markov chain as the noise in the image at <em>t</em>  depends on the pixels of the image on time <em>t - 1</em>.</p>
<!-- raw HTML omitted -->
<p>This diagram shows the diffusion process. It&rsquo;s a chain process that adds noise step by step till the image is completely destroyed and is dependent on the parameter <!-- raw HTML omitted --><!-- raw HTML omitted -->β<!-- raw HTML omitted --><!-- raw HTML omitted --> and α = 1 - <!-- raw HTML omitted --><!-- raw HTML omitted -->β<!-- raw HTML omitted --><!-- raw HTML omitted --></p>
<!-- raw HTML omitted -->
<p>This formula gives the image at time t given the image at time t=0. The parameters here are the cumilative sum of the parameters till time t.</p>
</li>
<li>
<h2 id="reverse-diffusion">Reverse Diffusion</h2>
<p>Now we need a neural network to predict the noise in a given image at particular timestamp t. We&rsquo;ll be using U-Net because it has the ability to use the information in the previous adjacent latent space. This gives the network attention and makes it possible to predict noise. The model is also given the timestamp as input by converitng it into a time embedding and adding it to different stages of the model.</p>
</li>
<li>
<h2 id="training">Training</h2>
</li>
</ul>
</section>

  
  

  
  
  
  <nav class="mt-24 flex rounded-lg bg-black/[3%] text-lg dark:bg-white/[8%]">
    
    <a
      class="flex w-1/2 items-center rounded-l-md p-6 pr-3 no-underline hover:bg-black/[2%] dark:hover:bg-white/[3%]"
      href="https://harikrishna-al.github.io/notes/posts/nerf_model/"
      ><span class="mr-1.5">←</span><span>NeRF</span></a
    >
    
    
  </nav>
  

  
  

  
  
</article>


    </main>

    <footer
  class="opaco mx-auto flex h-[5rem] max-w-3xl items-center px-8 text-[0.9em] opacity-60"
>
  <div class="mr-auto">
    &copy; 2023
    <a class="link" href="https://harikrishna-al.github.io/notes/">Notes</a>
  </div>
  <a class="link mx-6" href="https://gohugo.io/" rel="noopener" target="_blank"
    >Powered by Hugo️️</a
  >️
  <a
    class="link"
    href="https://github.com/nanxiaobei/hugo-paper"
    rel="noopener"
    target="_blank"
    >Theme Paper</a
  >
</footer>

  </body>
</html>
